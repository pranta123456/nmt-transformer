# nmt-transformer

This repository contains the implementation of the groundbreaking model architecture Transformer from the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762) and its pretraining for NMT from Germen to English on Multi30k Dataset.
 
![alt text](https://github.com/[pranta1234]/[nmt-transformer]/blob/[main]/images/image.jpg?raw=true)
