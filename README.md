# nmt-transformer

This repository contains the implementation of the groundbreaking model architecture Transformer from the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762) and its pretraining for NMT from Germen to English on Multi30k Dataset.
 
